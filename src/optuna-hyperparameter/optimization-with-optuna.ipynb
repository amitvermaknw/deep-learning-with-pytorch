{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e476ff80",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization with Optuna\n",
    "\n",
    "Welcome to the Optuna-based hyperparameter optimization tutorial! In this interactive notebook, you will explore world of hyperparameter tuning for a Convolutional Neural Network (CNN) specifically aimed at image classification using the CIFAR-10 dataset. Hyperparameter optimization is pivotal in enhancing model performance, making your models more accurate and efficient.\n",
    "\n",
    "Optuna, a robust and versatile library, plays a central role in automating and streamlining this process. It empowers you to navigate through complex hyperparameter spaces with ease. In this tutorial, you will engage with Optuna's core functionalities, and you'll also have the opportunity to construct a flexible CNN architecture. This adaptable design is essential for understanding how models can be fine-tuned effortlessly to suit various hyperparameter configurations.\n",
    "\n",
    "Throughout this session, you will:\n",
    "- Learn how to set up and execute an Optuna study, incorporating all essential elements required for effective hyperparameter optimization.\n",
    "- Perform a thorough analysis of the results to evaluate how different hyperparameters influence model performance, gaining insights into their practical impact.\n",
    "\n",
    "Additionally, this tutorial includes an optional section where you will compare two prevalent methods of hyperparameter optimization: Optuna's default sampling method (Tree-structured Parzen Estimator, or TPE) and the traditional Grid Search method. This comparison will not only highlight the strengths of Optuna but also provide a clearer perspective on how it can outperform conventional optimization techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7cc6f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amitvermaknw/Desktop/app/ML/deep-learning-with-pytorch/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from pprint import pprint\n",
    "import helper\n",
    "\n",
    "helper.set_seed(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872b364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad4877",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization for CNNs on CIFAR-10\n",
    "\n",
    "In this section, you explore the vital task of finding the optimal hyperparameters for a Convolutional Neural Network (CNN) tailored to the CIFAR-10 dataset. \n",
    "Utilizing Optuna, a sophisticated framework for hyperparameter optimization, your goal is to streamline and automate the process, ensuring efficiency and effectiveness. \n",
    "The selection of hyperparameters is notably intensive computationally and depends on various factors including the architecture of the model, the dataset characteristics, and the specific training processes involved. These elements, collectively and individually, have significant impacts on the performance outcomes of the model.\n",
    "\n",
    "### Defining a Flexible CNN Architecture\n",
    "\n",
    "The model architecture here is deliberately designed to be flexible, accommodating variability in its layers which is pivotal for adapting to different hyperparameter configurations suggested by Optuna during optimization trials.  \n",
    "The architecture is defined in a modular manner, allowing for easy adjustments and experimentation with different layer configurations, activation functions, and other hyperparameters. \n",
    "\n",
    "`FlexibleCNN` is a class that encapsulates the architecture of the CNN model:\n",
    "\n",
    "* **`__init__`**: The constructor initializes the model's feature extraction layers.\n",
    ">    * It constructs a series of convolutional blocks based on the `n_layers` parameter. Each block is a sequence of `nn.Conv2d`, `nn.ReLU`, and `nn.MaxPool2d`.\n",
    ">    * The `in_channels` for each block is set to the `out_channels` of the preceding block to ensure a seamless data flow.\n",
    ">    * All blocks are combined into a single `nn.Sequential` module assigned to the `.features` attribute, which handles feature extraction.\n",
    ">    * The classifier, `.classifier`, is initially set to `None` and will be constructed dynamically later.\n",
    " * **`_create_classifier`**: This helper method dynamically builds the classifier part of the network.\n",
    ">    * It's called during the first forward pass once the input size for the linear layers is known.\n",
    " * **`forward`**: This method defines the forward pass of the model.\n",
    ">    * The input `x` first passes through the `.features` layers.\n",
    ">    * The output from the feature extractor is flattened to determine the input size for the classifier.\n",
    ">    * If the `.classifier` has not been created yet, it calls `_create_classifier` to build it on the fly.\n",
    ">    * Finally, the flattened data is passed through the `.classifier` to produce the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83d5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A flexible Convolutional Neural Network with a dynamically created classifier.\n",
    "\n",
    "    This CNN's architecture is defined by the provided hyperparameters,\n",
    "    allowing for a variable number of convolutional layers. The classifier\n",
    "    (fully connected layers) is constructed during the first forward pass\n",
    "    to adapt to the output size of the convolutional feature extractor.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers, n_filters, kernel_sizes, dropout_rate, fc_size):\n",
    "        \"\"\"\n",
    "        Initializes the feature extraction part of the CNN.\n",
    "\n",
    "        Args:\n",
    "            n_layers: The number of convolutional blocks to create.\n",
    "            n_filters: A list of integers specifying the number of output\n",
    "                       filters for each convolutional block.\n",
    "            kernel_sizes: A list of integers specifying the kernel size for\n",
    "                          each convolutional layer.\n",
    "            dropout_rate: The dropout probability to be used in the classifier.\n",
    "            fc_size: The number of neurons in the hidden fully connected layer.\n",
    "        \"\"\"\n",
    "        super(FlexibleCNN, self).__init__()\n",
    "\n",
    "        #Initialize an empty list to hold the convolution blocks\n",
    "        blocks = []\n",
    "        #Set the initial number of input channels for RGB images\n",
    "        in_channels = 3\n",
    "\n",
    "        #Loop to construct each convolutional block\n",
    "        for i in range(n_layers):\n",
    "            #Get the parameters for current convolution layer\n",
    "            out_channels = n_filters[i]\n",
    "            kernel_size = kernel_sizes[i]\n",
    "\n",
    "            #Calculate padding to maintain the input spatial dimension('same' padding)\n",
    "            padding = (kernel_size-1) // 2\n",
    "\n",
    "            #Define a block as a sequence of conv, ReLU and MaxPool. layers\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "\n",
    "            #Add the newly created block to the list\n",
    "            blocks.append(block)\n",
    "\n",
    "            #Update the number of input channels for the next block\n",
    "            in_channels = out_channels\n",
    "\n",
    "        #Combine all blocks inot a single feature extractor module\n",
    "        self.features = nn.Sequential(*blocks)\n",
    "\n",
    "        #Store hyperparameters needed for building the classifier later\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.fc_size = fc_size\n",
    "\n",
    "        #The classifier will be initialized dynamically in the forward pass\n",
    "        self.classifier = None\n",
    "\n",
    "    def _create_classifier(self, flattened_size, device):\n",
    "        \"\"\"\n",
    "        Dynamically creates and initializes the classifier part of the network.\n",
    "\n",
    "        This helper method is called during the first forward pass to build the\n",
    "        fully connected layers based on the feature map size from the\n",
    "        convolutional base.\n",
    "\n",
    "        Args:\n",
    "            flattened_size: The number of input features for the first linear\n",
    "                            layer, determined from the flattened feature map.\n",
    "            device: The device to which the new classifier layers should be moved.\n",
    "        \"\"\"\n",
    "\n",
    "        #Define the classifier's architecture\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(flattened_size, self.fc_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(self.fc_size, 100)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x: The input tensor of shape (batch_size, channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            The output logits from the classifier.\n",
    "        \"\"\"\n",
    "        #Get the device of the input tensor to ensure consistency\n",
    "        device = x.device\n",
    "\n",
    "        #Pass the input through the feature extraction layer\n",
    "        x=self.features(x)\n",
    "\n",
    "        #Flatten the feature map to prepare it for the fully connected layers\n",
    "        flattened = torch.flatten(x, 1)\n",
    "        flattened_size = flattened.size(1)\n",
    "\n",
    "        #If the classifier has not been created yet, initialize it\n",
    "        if self.classifier is None:\n",
    "            self._create_classifier(flattened_size, device)\n",
    "\n",
    "        #pass the flattened feature through the classifier to get the final output\n",
    "        return self.classifier(flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182fe0c",
   "metadata": {},
   "source": [
    "## Defining the Optuna Objective Function\n",
    "\n",
    "The objective function is the core of the hyperparameter optimization process, being the function that Optuna will repeatedly call to evaluate different hyperparameter configurations.\n",
    "This function encapsulates the entire training and evaluation process, including the definition of the CNN model architecture, the optimizer, the data loaders, the training loop, and the evaluation metrics.\n",
    "Within this function, you define the search space for hyperparameters using `trial.suggest_*` methods, which allow Optuna to sample hyperparameters from a defined range or set of values. \n",
    "For a full list of available `suggest_*` methods, you can refer to the [Optuna documentation](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html).\n",
    "\n",
    "*The objective function is designed to return a single scalar value, which represents the performance of the model for the given hyperparameters*. \n",
    "In your case, the aim to maximize the accuracy of the model on the validation set, which is computed using the `evaluate_accuracy` function.\n",
    "\n",
    "**Dynamic Layer Initialization**: A noteworthy addition to this objective function is the initialization step involving a dummy input. Because the `FlexibleCNN` creates its classifier layers dynamically during the first forward pass, these parameters do not exist immediately after the model is instantiated.\n",
    "- **Why use a dummy input?** Passing data through the model forces it to calculate the flattened feature size and build the classifier layers. You must do this *before* defining the optimizer so that `model.parameters()` includes the classifier weights. Otherwise, the optimizer would only track the feature extractor, leaving the classifier untrained.\n",
    ">\n",
    "- **Why these dimensions?** The tensor `torch.randn(1, 3, 32, 32)` is used to mimic the structure of the CIFAR-10 dataset. It represents a single image (batch size of 1) with 3 color channels (RGB) and a resolution of `32x32` pixels.\n",
    "\n",
    "Observe that some hyperparameters are defined as fixed values, such as the number of epochs, the batch size, and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80ca065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, device):\n",
    "    \"\"\"\n",
    "    Defines the objective function for hyperparameter optimization using Optuna.\n",
    "\n",
    "    For each trial, this function samples a set of hyperparameters,\n",
    "    constructs a model, trains it for a fixed number of epochs, evaluates\n",
    "    its performance on a validation set, and returns the accuracy. Optuna\n",
    "    uses the returned accuracy to guide its search for the best\n",
    "    hyperparameter combination.\n",
    "\n",
    "    Args:\n",
    "        trial: An Optuna `Trial` object, used to sample hyperparameters.\n",
    "        device: The device ('cpu' or 'cuda') for model training and evaluation.\n",
    "\n",
    "    Returns:\n",
    "        The validation accuracy of the trained model as a float.\n",
    "    \"\"\"\n",
    "\n",
    "    #Sample hyperparameters for the feature extractor using the Optuna trial\n",
    "    n_layers = trial.suggest_int(\"n_layer\", 1, 3)\n",
    "    n_filters=[trial.suggest_int(f\"n_filter_{i}\", 16, 128) for i in range(n_layers)]\n",
    "    kernal_sizes = [trial.suggest_categorical(f\"kernel_size_{i}\", [3,5]) for i in range(n_layers)]\n",
    "\n",
    "    #Sample hyperparameters for the classifier\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    fc_size = trial.suggest_int(\"fc_size\", 64, 256)\n",
    "\n",
    "    #Instantiate the model with the sampled hyperparameters\n",
    "    model = FlexibleCNN(n_layers, n_filters, kernal_sizes, dropout_rate, fc_size).to(device)\n",
    "\n",
    "    #Initialize the dynamic classifier layer bt passing a dummy input through the model\n",
    "    #This ensure all parameters are instantiated before the optimizer is defined\n",
    "    dummy_input = torch.rand(1,3,32, 32).to(device)\n",
    "    model(dummy_input)\n",
    "\n",
    "    #Define fixed training parameters: lr, loss function and optimizer\n",
    "    learning_rate = 0.001\n",
    "    loss_fcn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "    #Define fixed daata loading parameters and crete data loader\n",
    "    batch_size=128\n",
    "    train_loader, val_loader = helper.get_dataset_dataloaders(batch_size=batch_size)\n",
    "\n",
    "    #Define the fixed number of epochs for training\n",
    "    n_epochs = 10\n",
    "\n",
    "    #Train model using a helper function\n",
    "    helper.train_model(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_fcn=loss_fcn,\n",
    "        train_dataloader=train_loader,\n",
    "        n_epochs=n_epochs,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    #Evaluate the trained model's accuracy on the validaation set\n",
    "    accuracy = helper.evaluate_accuracy(model, val_loader, device)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35fd771",
   "metadata": {},
   "source": [
    "## Running the Optuna Study\n",
    "\n",
    "Once that the objective function is defined, an Optuna study is created to manage the hyperparameter optimization process.\n",
    "The study is responsible for running the objective function multiple times with different hyperparameter configurations, allowing Optuna to explore the search space and find the best hyperparameters.\n",
    "In this case, your goal is to **maximize the accuracy** of the CNN model on the CIFAR-10 dataset, this is why we use `direction='maximize'` when creating the study.\n",
    "The `optimize` method of the study is called to start the optimization process, which will run the objective function for a defined number of trials.\n",
    "\n",
    "A lambda function is used to pass the device to the objective function, allowing the model to be trained on the specified device\n",
    "*Note*: you can also pass other parameters to the objective function using the lambda function, if needed.\n",
    "\n",
    "**NOTE:** the code below will take about 8 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ac3ad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:06:46,717]\u001b[0m A new study created in memory with name: no-name-be59388d-7752-4469-aab3-f2b03f6c4c6f\u001b[0m\n",
      "/Users/amitvermaknw/Desktop/app/ML/deep-learning-with-pytorch/.venv/lib/python3.14/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n",
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:07<00:05,  1.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:14<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.6576\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:07:03,158]\u001b[0m Trial 0 finished with value: 0.5745 and parameters: {'n_layer': 1, 'n_filter_0': 120, 'kernel_size_0': 3, 'dropout_rate': 0.25596530447594396, 'fc_size': 187}. Best is trial 0 with value: 0.5745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:06<00:04,  1.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.6073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:11<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 1.3762\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:07:15,534]\u001b[0m Trial 1 finished with value: 0.4955 and parameters: {'n_layer': 3, 'n_filter_0': 20, 'n_filter_1': 36, 'n_filter_2': 37, 'kernel_size_0': 3, 'kernel_size_1': 3, 'kernel_size_2': 5, 'dropout_rate': 0.2963825816538338, 'fc_size': 74}. Best is trial 0 with value: 0.5745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:07<00:05,  1.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.4369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:14<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 1.2246\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:07:31,201]\u001b[0m Trial 2 finished with value: 0.57 and parameters: {'n_layer': 2, 'n_filter_0': 54, 'n_filter_1': 16, 'kernel_size_0': 5, 'kernel_size_1': 5, 'dropout_rate': 0.446500524419426, 'fc_size': 255}. Best is trial 0 with value: 0.5745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:08<00:05,  1.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.3812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 1.0123\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:07:47,829]\u001b[0m Trial 3 finished with value: 0.58 and parameters: {'n_layer': 3, 'n_filter_0': 56, 'n_filter_1': 55, 'n_filter_2': 82, 'kernel_size_0': 3, 'kernel_size_1': 3, 'kernel_size_2': 5, 'dropout_rate': 0.2685762334254175, 'fc_size': 188}. Best is trial 3 with value: 0.58.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:07<00:05,  1.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.0785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.6771\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:08:03,606]\u001b[0m Trial 4 finished with value: 0.589 and parameters: {'n_layer': 1, 'n_filter_0': 89, 'kernel_size_0': 5, 'dropout_rate': 0.2635541398295715, 'fc_size': 165}. Best is trial 4 with value: 0.589.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:16<00:12,  3.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.3549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:32<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 1.0020\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:08:37,363]\u001b[0m Trial 5 finished with value: 0.595 and parameters: {'n_layer': 3, 'n_filter_0': 118, 'n_filter_1': 84, 'n_filter_2': 86, 'kernel_size_0': 5, 'kernel_size_1': 5, 'kernel_size_2': 3, 'dropout_rate': 0.2479710439634352, 'fc_size': 154}. Best is trial 5 with value: 0.595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:07<00:05,  1.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.4916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:15<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 1.1903\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:08:53,437]\u001b[0m Trial 6 finished with value: 0.556 and parameters: {'n_layer': 3, 'n_filter_0': 125, 'n_filter_1': 42, 'n_filter_2': 95, 'kernel_size_0': 3, 'kernel_size_1': 3, 'kernel_size_2': 3, 'dropout_rate': 0.4468695081428332, 'fc_size': 170}. Best is trial 5 with value: 0.595.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:13<00:09,  2.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.2153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:26<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.7674\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:09:21,238]\u001b[0m Trial 7 finished with value: 0.616 and parameters: {'n_layer': 2, 'n_filter_0': 97, 'n_filter_1': 94, 'kernel_size_0': 3, 'kernel_size_1': 5, 'dropout_rate': 0.2307979761624401, 'fc_size': 219}. Best is trial 7 with value: 0.616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:09<00:06,  1.70s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.2993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:18<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.9408\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:09:40,799]\u001b[0m Trial 8 finished with value: 0.621 and parameters: {'n_layer': 2, 'n_filter_0': 84, 'n_filter_1': 35, 'kernel_size_0': 5, 'kernel_size_1': 5, 'dropout_rate': 0.24824192835781644, 'fc_size': 232}. Best is trial 8 with value: 0.621.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:07<00:05,  1.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:14<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.9993\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:09:56,628]\u001b[0m Trial 9 finished with value: 0.5655 and parameters: {'n_layer': 2, 'n_filter_0': 116, 'n_filter_1': 42, 'kernel_size_0': 3, 'kernel_size_1': 3, 'dropout_rate': 0.21165355874796218, 'fc_size': 171}. Best is trial 8 with value: 0.621.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:07<00:05,  1.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:14<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.6011\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:10:12,340]\u001b[0m Trial 10 finished with value: 0.6015 and parameters: {'n_layer': 1, 'n_filter_0': 71, 'kernel_size_0': 5, 'dropout_rate': 0.11510774472990823, 'fc_size': 118}. Best is trial 8 with value: 0.621.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:16<00:11,  2.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.0675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:32<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.5488\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:10:45,833]\u001b[0m Trial 11 finished with value: 0.6195 and parameters: {'n_layer': 2, 'n_filter_0': 95, 'n_filter_1': 116, 'kernel_size_0': 5, 'kernel_size_1': 5, 'dropout_rate': 0.15041115624979712, 'fc_size': 243}. Best is trial 8 with value: 0.621.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:16<00:11,  2.95s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:32<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.5347\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:11:19,046]\u001b[0m Trial 12 finished with value: 0.6255 and parameters: {'n_layer': 2, 'n_filter_0': 90, 'n_filter_1': 123, 'kernel_size_0': 5, 'kernel_size_1': 5, 'dropout_rate': 0.12530665372694055, 'fc_size': 251}. Best is trial 12 with value: 0.6255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:14<00:10,  2.69s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.1573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:29<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.7387\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:11:49,091]\u001b[0m Trial 13 finished with value: 0.619 and parameters: {'n_layer': 2, 'n_filter_0': 77, 'n_filter_1': 124, 'kernel_size_0': 5, 'kernel_size_1': 5, 'dropout_rate': 0.35688679734193873, 'fc_size': 219}. Best is trial 12 with value: 0.6255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:08<00:06,  1.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.2605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:16<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.8807\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:12:07,064]\u001b[0m Trial 14 finished with value: 0.5985 and parameters: {'n_layer': 2, 'n_filter_0': 59, 'n_filter_1': 73, 'kernel_size_0': 5, 'kernel_size_1': 5, 'dropout_rate': 0.3560107539753389, 'fc_size': 225}. Best is trial 12 with value: 0.6255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:06<00:04,  1.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.1487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:13<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.7444\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:12:20,997]\u001b[0m Trial 15 finished with value: 0.544 and parameters: {'n_layer': 1, 'n_filter_0': 30, 'kernel_size_0': 5, 'dropout_rate': 0.1736941549425369, 'fc_size': 239}. Best is trial 12 with value: 0.6255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:17<00:13,  3.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:35<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.6555\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:12:57,587]\u001b[0m Trial 16 finished with value: 0.5995 and parameters: {'n_layer': 2, 'n_filter_0': 103, 'n_filter_1': 102, 'kernel_size_0': 5, 'kernel_size_1': 5, 'dropout_rate': 0.10958275363323897, 'fc_size': 201}. Best is trial 12 with value: 0.6255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:07<00:05,  1.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.1865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:14<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.8291\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:13:13,222]\u001b[0m Trial 17 finished with value: 0.594 and parameters: {'n_layer': 1, 'n_filter_0': 80, 'kernel_size_0': 5, 'dropout_rate': 0.3363314813708626, 'fc_size': 126}. Best is trial 12 with value: 0.6255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:14<00:10,  2.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.3448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:28<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 0.9055\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:13:42,647]\u001b[0m Trial 18 finished with value: 0.593 and parameters: {'n_layer': 3, 'n_filter_0': 106, 'n_filter_1': 62, 'n_filter_2': 128, 'kernel_size_0': 5, 'kernel_size_1': 5, 'kernel_size_2': 5, 'dropout_rate': 0.17688786100126325, 'fc_size': 206}. Best is trial 12 with value: 0.6255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 6:  60%|██████    | 6/10 [00:07<00:05,  1.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.4231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Current Epoch: 10: 100%|██████████| 10/10 [00:14<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 1.1666\n",
      "Training complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-30 11:13:58,399]\u001b[0m Trial 19 finished with value: 0.563 and parameters: {'n_layer': 2, 'n_filter_0': 40, 'n_filter_1': 23, 'kernel_size_0': 5, 'kernel_size_1': 5, 'dropout_rate': 0.411496977086487, 'fc_size': 252}. Best is trial 12 with value: 0.6255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimie the objective function\n",
    "study = optuna.create_study(direction='maximize') #The goal in this case is to maximize accuracy\n",
    "\n",
    "#Start the optimization process \n",
    "n_trials = 20\n",
    "study.optimize(lambda trial: objective(trial, device), n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9feaec3",
   "metadata": {},
   "source": [
    "### Analyzing the Results\n",
    "After the optimization process is complete, you can analyze the results to understand which hyperparameters yielded the best performance.\n",
    "The `study` object contains a wealth of information about the trials, including the hyperparameters sampled, the corresponding performance metrics, and the best trial.\n",
    "\n",
    "You can access the full DataFrame of trials using the `trials_dataframe()` method, which provides a comprehensive overview of all the trials conducted during the optimization process.\n",
    "This DataFrame includes columns for the trial number, hyperparameters, and the objective value (in our case, the accuracy).\n",
    "\n",
    "To access the best hyperparameters and the best trial, you can use the `best_trial` attributes of the study object.\n",
    "\n",
    "**Note:** these results may change every time you re-run the training study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "707d220f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_dropout_rate</th>\n",
       "      <th>params_fc_size</th>\n",
       "      <th>params_kernel_size_0</th>\n",
       "      <th>params_kernel_size_1</th>\n",
       "      <th>params_kernel_size_2</th>\n",
       "      <th>params_n_filter_0</th>\n",
       "      <th>params_n_filter_1</th>\n",
       "      <th>params_n_filter_2</th>\n",
       "      <th>params_n_layer</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>2026-01-30 11:06:46.718465</td>\n",
       "      <td>2026-01-30 11:07:03.158754</td>\n",
       "      <td>0 days 00:00:16.440289</td>\n",
       "      <td>0.255965</td>\n",
       "      <td>187</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>2026-01-30 11:07:03.159221</td>\n",
       "      <td>2026-01-30 11:07:15.534493</td>\n",
       "      <td>0 days 00:00:12.375272</td>\n",
       "      <td>0.296383</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>2026-01-30 11:07:15.534888</td>\n",
       "      <td>2026-01-30 11:07:31.201139</td>\n",
       "      <td>0 days 00:00:15.666251</td>\n",
       "      <td>0.446501</td>\n",
       "      <td>255</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>2026-01-30 11:07:31.201581</td>\n",
       "      <td>2026-01-30 11:07:47.829249</td>\n",
       "      <td>0 days 00:00:16.627668</td>\n",
       "      <td>0.268576</td>\n",
       "      <td>188</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>56</td>\n",
       "      <td>55.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>2026-01-30 11:07:47.829597</td>\n",
       "      <td>2026-01-30 11:08:03.606687</td>\n",
       "      <td>0 days 00:00:15.777090</td>\n",
       "      <td>0.263554</td>\n",
       "      <td>165</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>2026-01-30 11:08:03.607125</td>\n",
       "      <td>2026-01-30 11:08:37.363217</td>\n",
       "      <td>0 days 00:00:33.756092</td>\n",
       "      <td>0.247971</td>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5560</td>\n",
       "      <td>2026-01-30 11:08:37.363562</td>\n",
       "      <td>2026-01-30 11:08:53.436992</td>\n",
       "      <td>0 days 00:00:16.073430</td>\n",
       "      <td>0.446870</td>\n",
       "      <td>170</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>125</td>\n",
       "      <td>42.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>2026-01-30 11:08:53.437292</td>\n",
       "      <td>2026-01-30 11:09:21.238821</td>\n",
       "      <td>0 days 00:00:27.801529</td>\n",
       "      <td>0.230798</td>\n",
       "      <td>219</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.6210</td>\n",
       "      <td>2026-01-30 11:09:21.239173</td>\n",
       "      <td>2026-01-30 11:09:40.799672</td>\n",
       "      <td>0 days 00:00:19.560499</td>\n",
       "      <td>0.248242</td>\n",
       "      <td>232</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.5655</td>\n",
       "      <td>2026-01-30 11:09:40.799951</td>\n",
       "      <td>2026-01-30 11:09:56.628444</td>\n",
       "      <td>0 days 00:00:15.828493</td>\n",
       "      <td>0.211654</td>\n",
       "      <td>171</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.6015</td>\n",
       "      <td>2026-01-30 11:09:56.628815</td>\n",
       "      <td>2026-01-30 11:10:12.340227</td>\n",
       "      <td>0 days 00:00:15.711412</td>\n",
       "      <td>0.115108</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.6195</td>\n",
       "      <td>2026-01-30 11:10:12.340568</td>\n",
       "      <td>2026-01-30 11:10:45.833761</td>\n",
       "      <td>0 days 00:00:33.493193</td>\n",
       "      <td>0.150411</td>\n",
       "      <td>243</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>2026-01-30 11:10:45.834188</td>\n",
       "      <td>2026-01-30 11:11:19.046671</td>\n",
       "      <td>0 days 00:00:33.212483</td>\n",
       "      <td>0.125307</td>\n",
       "      <td>251</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>2026-01-30 11:11:19.047072</td>\n",
       "      <td>2026-01-30 11:11:49.091568</td>\n",
       "      <td>0 days 00:00:30.044496</td>\n",
       "      <td>0.356887</td>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.5985</td>\n",
       "      <td>2026-01-30 11:11:49.091976</td>\n",
       "      <td>2026-01-30 11:12:07.064648</td>\n",
       "      <td>0 days 00:00:17.972672</td>\n",
       "      <td>0.356011</td>\n",
       "      <td>225</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>2026-01-30 11:12:07.065168</td>\n",
       "      <td>2026-01-30 11:12:20.997108</td>\n",
       "      <td>0 days 00:00:13.931940</td>\n",
       "      <td>0.173694</td>\n",
       "      <td>239</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.5995</td>\n",
       "      <td>2026-01-30 11:12:20.997474</td>\n",
       "      <td>2026-01-30 11:12:57.587863</td>\n",
       "      <td>0 days 00:00:36.590389</td>\n",
       "      <td>0.109583</td>\n",
       "      <td>201</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>2026-01-30 11:12:57.588265</td>\n",
       "      <td>2026-01-30 11:13:13.221962</td>\n",
       "      <td>0 days 00:00:15.633697</td>\n",
       "      <td>0.336331</td>\n",
       "      <td>126</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.5930</td>\n",
       "      <td>2026-01-30 11:13:13.222498</td>\n",
       "      <td>2026-01-30 11:13:42.646966</td>\n",
       "      <td>0 days 00:00:29.424468</td>\n",
       "      <td>0.176888</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>106</td>\n",
       "      <td>62.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.5630</td>\n",
       "      <td>2026-01-30 11:13:42.647280</td>\n",
       "      <td>2026-01-30 11:13:58.399050</td>\n",
       "      <td>0 days 00:00:15.751770</td>\n",
       "      <td>0.411497</td>\n",
       "      <td>252</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number   value             datetime_start          datetime_complete  \\\n",
       "0        0  0.5745 2026-01-30 11:06:46.718465 2026-01-30 11:07:03.158754   \n",
       "1        1  0.4955 2026-01-30 11:07:03.159221 2026-01-30 11:07:15.534493   \n",
       "2        2  0.5700 2026-01-30 11:07:15.534888 2026-01-30 11:07:31.201139   \n",
       "3        3  0.5800 2026-01-30 11:07:31.201581 2026-01-30 11:07:47.829249   \n",
       "4        4  0.5890 2026-01-30 11:07:47.829597 2026-01-30 11:08:03.606687   \n",
       "5        5  0.5950 2026-01-30 11:08:03.607125 2026-01-30 11:08:37.363217   \n",
       "6        6  0.5560 2026-01-30 11:08:37.363562 2026-01-30 11:08:53.436992   \n",
       "7        7  0.6160 2026-01-30 11:08:53.437292 2026-01-30 11:09:21.238821   \n",
       "8        8  0.6210 2026-01-30 11:09:21.239173 2026-01-30 11:09:40.799672   \n",
       "9        9  0.5655 2026-01-30 11:09:40.799951 2026-01-30 11:09:56.628444   \n",
       "10      10  0.6015 2026-01-30 11:09:56.628815 2026-01-30 11:10:12.340227   \n",
       "11      11  0.6195 2026-01-30 11:10:12.340568 2026-01-30 11:10:45.833761   \n",
       "12      12  0.6255 2026-01-30 11:10:45.834188 2026-01-30 11:11:19.046671   \n",
       "13      13  0.6190 2026-01-30 11:11:19.047072 2026-01-30 11:11:49.091568   \n",
       "14      14  0.5985 2026-01-30 11:11:49.091976 2026-01-30 11:12:07.064648   \n",
       "15      15  0.5440 2026-01-30 11:12:07.065168 2026-01-30 11:12:20.997108   \n",
       "16      16  0.5995 2026-01-30 11:12:20.997474 2026-01-30 11:12:57.587863   \n",
       "17      17  0.5940 2026-01-30 11:12:57.588265 2026-01-30 11:13:13.221962   \n",
       "18      18  0.5930 2026-01-30 11:13:13.222498 2026-01-30 11:13:42.646966   \n",
       "19      19  0.5630 2026-01-30 11:13:42.647280 2026-01-30 11:13:58.399050   \n",
       "\n",
       "                 duration  params_dropout_rate  params_fc_size  \\\n",
       "0  0 days 00:00:16.440289             0.255965             187   \n",
       "1  0 days 00:00:12.375272             0.296383              74   \n",
       "2  0 days 00:00:15.666251             0.446501             255   \n",
       "3  0 days 00:00:16.627668             0.268576             188   \n",
       "4  0 days 00:00:15.777090             0.263554             165   \n",
       "5  0 days 00:00:33.756092             0.247971             154   \n",
       "6  0 days 00:00:16.073430             0.446870             170   \n",
       "7  0 days 00:00:27.801529             0.230798             219   \n",
       "8  0 days 00:00:19.560499             0.248242             232   \n",
       "9  0 days 00:00:15.828493             0.211654             171   \n",
       "10 0 days 00:00:15.711412             0.115108             118   \n",
       "11 0 days 00:00:33.493193             0.150411             243   \n",
       "12 0 days 00:00:33.212483             0.125307             251   \n",
       "13 0 days 00:00:30.044496             0.356887             219   \n",
       "14 0 days 00:00:17.972672             0.356011             225   \n",
       "15 0 days 00:00:13.931940             0.173694             239   \n",
       "16 0 days 00:00:36.590389             0.109583             201   \n",
       "17 0 days 00:00:15.633697             0.336331             126   \n",
       "18 0 days 00:00:29.424468             0.176888             206   \n",
       "19 0 days 00:00:15.751770             0.411497             252   \n",
       "\n",
       "    params_kernel_size_0  params_kernel_size_1  params_kernel_size_2  \\\n",
       "0                      3                   NaN                   NaN   \n",
       "1                      3                   3.0                   5.0   \n",
       "2                      5                   5.0                   NaN   \n",
       "3                      3                   3.0                   5.0   \n",
       "4                      5                   NaN                   NaN   \n",
       "5                      5                   5.0                   3.0   \n",
       "6                      3                   3.0                   3.0   \n",
       "7                      3                   5.0                   NaN   \n",
       "8                      5                   5.0                   NaN   \n",
       "9                      3                   3.0                   NaN   \n",
       "10                     5                   NaN                   NaN   \n",
       "11                     5                   5.0                   NaN   \n",
       "12                     5                   5.0                   NaN   \n",
       "13                     5                   5.0                   NaN   \n",
       "14                     5                   5.0                   NaN   \n",
       "15                     5                   NaN                   NaN   \n",
       "16                     5                   5.0                   NaN   \n",
       "17                     5                   NaN                   NaN   \n",
       "18                     5                   5.0                   5.0   \n",
       "19                     5                   5.0                   NaN   \n",
       "\n",
       "    params_n_filter_0  params_n_filter_1  params_n_filter_2  params_n_layer  \\\n",
       "0                 120                NaN                NaN               1   \n",
       "1                  20               36.0               37.0               3   \n",
       "2                  54               16.0                NaN               2   \n",
       "3                  56               55.0               82.0               3   \n",
       "4                  89                NaN                NaN               1   \n",
       "5                 118               84.0               86.0               3   \n",
       "6                 125               42.0               95.0               3   \n",
       "7                  97               94.0                NaN               2   \n",
       "8                  84               35.0                NaN               2   \n",
       "9                 116               42.0                NaN               2   \n",
       "10                 71                NaN                NaN               1   \n",
       "11                 95              116.0                NaN               2   \n",
       "12                 90              123.0                NaN               2   \n",
       "13                 77              124.0                NaN               2   \n",
       "14                 59               73.0                NaN               2   \n",
       "15                 30                NaN                NaN               1   \n",
       "16                103              102.0                NaN               2   \n",
       "17                 80                NaN                NaN               1   \n",
       "18                106               62.0              128.0               3   \n",
       "19                 40               23.0                NaN               2   \n",
       "\n",
       "       state  \n",
       "0   COMPLETE  \n",
       "1   COMPLETE  \n",
       "2   COMPLETE  \n",
       "3   COMPLETE  \n",
       "4   COMPLETE  \n",
       "5   COMPLETE  \n",
       "6   COMPLETE  \n",
       "7   COMPLETE  \n",
       "8   COMPLETE  \n",
       "9   COMPLETE  \n",
       "10  COMPLETE  \n",
       "11  COMPLETE  \n",
       "12  COMPLETE  \n",
       "13  COMPLETE  \n",
       "14  COMPLETE  \n",
       "15  COMPLETE  \n",
       "16  COMPLETE  \n",
       "17  COMPLETE  \n",
       "18  COMPLETE  \n",
       "19  COMPLETE  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract the dataframe with the result \n",
    "df = study.trials_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d61b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:\n",
      "Value Accuracy: 0.6255\n",
      "Hyperpaameters:\n",
      "{'n_layer': 2, 'n_filter_0': 90, 'n_filter_1': 123, 'kernel_size_0': 5, 'kernel_size_1': 5, 'dropout_rate': 0.12530665372694055, 'fc_size': 251}\n"
     ]
    }
   ],
   "source": [
    "#Extract and print the best trial\n",
    "best_trial = study.best_trial\n",
    "print(\"Best Trial:\")\n",
    "print(f\"Value Accuracy: {best_trial.value:.4f}\")\n",
    "\n",
    "print(\"Hyperpaameters:\")\n",
    "print(best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4de228",
   "metadata": {},
   "source": [
    "## Visualizing the Results\n",
    "\n",
    "Optuna provides several built-in visualization functions to help analyze the results of the hyperparameter optimization process.\n",
    "These visualizations can provide valuable insights into the optimization process and the impact of different hyperparameters on the model's performance:\n",
    "- `plot_optimization_history`: This plot shows the optimization history of the objective function, allowing you to see how the performance of the model improved over time. It provides a visual representation of the objective values (in this case, accuracy) across different trials.\n",
    " \n",
    "- `plot_param_importances`: This plot shows the importance of each hyperparameter in the optimization process. It helps identify which hyperparameters had the most significant impact on the model's performance, allowing you to focus on the most influential hyperparameters in future experiments.\n",
    "\n",
    "- `plot_parallel_coordinate`: This plot visualizes the relationship between different hyperparameters and the objective function. It allows you to see how different hyperparameter configurations affected the model's performance, providing insights into the interactions between hyperparameters and their impact on the objective value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81053d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the optimization history\n",
    "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "plt.title(\"Optimization History\")\n",
    "plt.show()\n",
    "\n",
    "#Importance of hyperparameters\n",
    "optuna.visualization.matplotlib.plot_param_importances(study)\n",
    "plt.show()\n",
    "\n",
    "ax = optuna.visualization.matplotlib.plot_parallel_coordinate(\n",
    "    study, params=['n_layers', 'n_filters_0', 'kernel_size_0', 'dropout_rate', 'fc_size']\n",
    ")\n",
    "\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(12, 6, forward=True)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
